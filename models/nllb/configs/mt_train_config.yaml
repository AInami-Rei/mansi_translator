seed_everything: 0
trainer:
  accelerator: auto
  devices: auto
  strategy: auto
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  precision: bf16-mixed
  gradient_clip_algorithm: norm
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  max_epochs: 10
  default_root_dir: /home/ai_talent_hub_hack_2024/checkpoints
  val_check_interval: 0.1
  fast_dev_run: False
  profiler: simple
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        patience: 5
        monitor: val_loss
        min_delta: 0.001
        mode: min
        check_finite: True
        verbose: True
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: /home/ai_talent_hub_hack_2024/checkpoints
        filename: nllb600m-{epoch:02d}-{val_loss:.2f}
        monitor: val_loss
        save_top_k: 1
        mode: min
        verbose: True
model:
  class_path: mt_model.MachineTranslationModel
  init_args:
    model_name_or_path: facebook/nllb-200-3.3B
    task_name: NLLB3.3b_lora_main_mansi_corpus
    split_name: train
    embed_resizing: True
    tokenizer_path: /home/ai_talent_hub_hack_2024/checkpoints/nllb_ft_tokenizer-rus-mans
    trained_spm_path: /home/ai_talent_hub_hack_2024/myv-nmt/spm_nllb_mansi_268k.model
    # ckpt_path:
    add_lora: True
    warmup_ratio: 0.1
    lora_r: 128
    lora_alpha: 128
    learning_rate: 1e-4
    scheduler_type: constant_with_warmup
    config_file: /home/ai_talent_hub_hack_2024/mansi_translator/models/configs/mt_train_config.yaml
data:
  class_path: mt_data.DataModule
  init_args:
    dataset_class: mt_datasets.MachineTranslationDataset
<<<<<<< HEAD:models/nllb/configs/mt_train_config.yaml
    train_data_path:
    val_data_path:
    test_data_path:
    spm_trained_path: /home/ai_talent_hub_hack_2024/myv-nmt/spm_nllb_mansi_268k.model
    data_processing: False
    batch_size: 100
=======
    train_data_path: /home/ai_talent_hub_hack_2024/train_data.csv
    val_data_path: /home/ai_talent_hub_hack_2024/val_data.csv
    test_data_path: /home/ai_talent_hub_hack_2024/test_data.csv
    data_processing: True
    batch_size: 4
>>>>>>> e6e7d92 (models/__pycache__):models/configs/mt_train_config.yaml
    num_workers: 16
    model_max_length: 512
